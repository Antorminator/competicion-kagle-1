{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Competición Kaggle: Titanic - Machine Learning from Disaster\n","\n","Es este notebook se detalla el desarrollo de un modelo de inteligencia artificial para participar en la competición de Kaggle **[\"Titanic - Machine Learning from Disaster\"](https://www.kaggle.com/c/titanic)**, que reta a predecir la supervivencia de los viajeros en la desastre del Titanic en base a una serie de variables.\n","\n","Como objetivo propuesto, se intenta que el modelo desarrollado alcance una puntuación superior al **0.7755**."]},{"cell_type":"markdown","metadata":{},"source":["## Carga de los datos\n","\n","Como paso inicial, cargamos en un dataframe de Pandas los datos de entrenamiento contenidos en el fichero train.csv, proporcionado en la página de la competición:"]},{"cell_type":"code","execution_count":132,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":132,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","train_data = pd.read_csv(\"train.csv\")\n","train_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["Visualizando el dataframe podemos explorar las *features* que contiene nuestro dataset.\n","\n","Adicionalmente, cargamos también los datos de test que se nos proporcionan, para poder evaluar a priori nuestro modelo antes de mandarlo a puntuar en la plataforma Kaggle:"]},{"cell_type":"code","execution_count":133,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>3</td>\n","      <td>Kelly, Mr. James</td>\n","      <td>male</td>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>330911</td>\n","      <td>7.8292</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>3</td>\n","      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n","      <td>female</td>\n","      <td>47.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>363272</td>\n","      <td>7.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>2</td>\n","      <td>Myles, Mr. Thomas Francis</td>\n","      <td>male</td>\n","      <td>62.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>240276</td>\n","      <td>9.6875</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>895</td>\n","      <td>3</td>\n","      <td>Wirz, Mr. Albert</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>315154</td>\n","      <td>8.6625</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>896</td>\n","      <td>3</td>\n","      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n","      <td>female</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3101298</td>\n","      <td>12.2875</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Pclass                                          Name     Sex  \\\n","0          892       3                              Kelly, Mr. James    male   \n","1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n","2          894       2                     Myles, Mr. Thomas Francis    male   \n","3          895       3                              Wirz, Mr. Albert    male   \n","4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n","\n","    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n","0  34.5      0      0   330911   7.8292   NaN        Q  \n","1  47.0      1      0   363272   7.0000   NaN        S  \n","2  62.0      0      0   240276   9.6875   NaN        Q  \n","3  27.0      0      0   315154   8.6625   NaN        S  \n","4  22.0      1      1  3101298  12.2875   NaN        S  "]},"execution_count":133,"metadata":{},"output_type":"execute_result"}],"source":["test_data = pd.read_csv(\"test.csv\")\n","test_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["De la exposición del problema a tratar, y como podemos deducir también al visualizar ambos dataset, nuestra columna objetivo se denominan **Survived**."]},{"cell_type":"markdown","metadata":{},"source":["## Exploración y tratamiento de los datos\n"]},{"cell_type":"markdown","metadata":{},"source":["A continuación hacemos una exploración inicial de todo el dataset de entrenamiento, para visualizar las estadisticas de las distintas features:"]},{"cell_type":"code","execution_count":134,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 12 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  891 non-null    int64  \n"," 1   Survived     891 non-null    int64  \n"," 2   Pclass       891 non-null    int64  \n"," 3   Name         891 non-null    object \n"," 4   Sex          891 non-null    object \n"," 5   Age          714 non-null    float64\n"," 6   SibSp        891 non-null    int64  \n"," 7   Parch        891 non-null    int64  \n"," 8   Ticket       891 non-null    object \n"," 9   Fare         891 non-null    float64\n"," 10  Cabin        204 non-null    object \n"," 11  Embarked     889 non-null    object \n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 83.7+ KB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>714.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>446.000000</td>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>29.699118</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.353842</td>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>14.526497</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>223.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>20.125000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>446.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>28.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>668.500000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>38.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>891.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PassengerId    Survived      Pclass         Age       SibSp  \\\n","count   891.000000  891.000000  891.000000  714.000000  891.000000   \n","mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n","std     257.353842    0.486592    0.836071   14.526497    1.102743   \n","min       1.000000    0.000000    1.000000    0.420000    0.000000   \n","25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n","50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n","75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n","max     891.000000    1.000000    3.000000   80.000000    8.000000   \n","\n","            Parch        Fare  \n","count  891.000000  891.000000  \n","mean     0.381594   32.204208  \n","std      0.806057   49.693429  \n","min      0.000000    0.000000  \n","25%      0.000000    7.910400  \n","50%      0.000000   14.454200  \n","75%      0.000000   31.000000  \n","max      6.000000  512.329200  "]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["train_data.info()\n","train_data.describe()"]},{"cell_type":"markdown","metadata":{},"source":["Tras la exploración inicial, y habiendo revisado la descripción proporcionada por Kaggle de cada columna, se pasa a seleccionar las features consideradas relevantes para el tratamiento del problema:"]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Número valores únicos en  Pclass :  3\n","[3 1 2]\n","Número de NA:  0\n","Número valores únicos en  Sex :  2\n","['male' 'female']\n","Número de NA:  0\n","Número valores únicos en  Age :  88\n","Número de NA:  177\n","Número valores únicos en  SibSp :  7\n","[1 0 3 4 2 5 8]\n","Número de NA:  0\n","Número valores únicos en  Parch :  7\n","[0 1 2 5 3 4 6]\n","Número de NA:  0\n","Número valores únicos en  Fare :  248\n","Número de NA:  0\n","Número valores únicos en  Embarked :  3\n","['S' 'C' 'Q' nan]\n","Número de NA:  2\n"]}],"source":["features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n","\n","for column in features:\n","    \n","    valores_unicos = train_data[column].nunique()\n","    \n","    print('Número valores únicos en ',column,': ',valores_unicos)\n","    if valores_unicos < 10:\n","        print(train_data[column].unique())\n","    \n","    print('Número de NA: ',train_data[column].isna().sum())"]},{"cell_type":"markdown","metadata":{},"source":["Analizando mas detalladamente los valores concretos de cada columna, vemos que en Age y Embarked hay datos faltantes. Registramos la columna Age para darle un tratamiento extra y suprimimos directamente los 2 registros con nan en Embarked:"]},{"cell_type":"code","execution_count":136,"metadata":{},"outputs":[],"source":["features_with_na = [\"Age\"]\n","train_data.dropna(subset=['Embarked'], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Creación del modelo de aprendizaje automático\n","\n","En este notebook se utilizará un modelo de tipo **HistGradientBoostingClassifier**, un modelo basado en árboles que utiliza histogramas para acelerar su velocidad de predicción. Se utilizará en un pipeline al que se le proporcionará además los preprocesadores SimpleImputer para las categorías con valores NA y un OrdinalEncoder en general para todas. Se hace uso del preprocesador OrdinalEncoder para evitar la expansión innecesaria del dataset, aprovechando para ello que los modelos basados en árboles no se ven afectados por el orden de los datos."]},{"cell_type":"code","execution_count":137,"metadata":{"_kg_hide-output":false,"trusted":true},"outputs":[],"source":["# Definición de los preprocesadores\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.compose import ColumnTransformer\n","\n","\n","ordinal_preprocessor = OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n","                                       unknown_value=-1)\n","\n","median_imputer = SimpleImputer(strategy=\"median\")\n","\n","preprocessor = ColumnTransformer([\n","    ('median_imputer', median_imputer, features_with_na),\n","    ('ordinal_preprocessor', ordinal_preprocessor, features)\n","])\n"]},{"cell_type":"code","execution_count":138,"metadata":{},"outputs":[],"source":["# Definición del pipeline con el modelo HistGradientBoostingClassifier\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","\n","model = Pipeline([\n","    (\"preprocessor\", preprocessor),\n","    (\"classifier\", HistGradientBoostingClassifier(random_state=42)),\n","])"]},{"cell_type":"markdown","metadata":{},"source":["Para buscar la mejor configuración del modelo, se hace uso de RandomizedSearchCV para obtener la mejor combinación de hiperparámetros. Para ello, importamos la función loguniform para generar números float aleatorios y creamos otra llamada loguniform_int, que sería homóloga a la anterior pero para números enteros:"]},{"cell_type":"code","execution_count":139,"metadata":{},"outputs":[],"source":["from scipy.stats import loguniform\n","\n","\n","class loguniform_int:\n","    \"\"\"Integer valued version of the log-uniform distribution\"\"\"\n","    def __init__(self, a, b):\n","        self._distribution = loguniform(a, b)\n","\n","    def rvs(self, *args, **kwargs):\n","        \"\"\"Random variable sample\"\"\"\n","        return self._distribution.rvs(*args, **kwargs).astype(int)"]},{"cell_type":"code","execution_count":140,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","# Definición de hiperparámetros a ajustar\n","\n","param_distributions = {\n","    'classifier__l2_regularization': loguniform(1e-6, 1e3),\n","    'classifier__learning_rate': loguniform(0.001, 10),\n","    'classifier__max_leaf_nodes': loguniform_int(2, 256),\n","    'classifier__min_samples_leaf': loguniform_int(1, 100),\n","    'classifier__max_bins': loguniform_int(2, 255),\n","    'classifier__max_depth': loguniform_int(2, 500)\n","}\n","\n","model_random_search = RandomizedSearchCV(\n","    model, param_distributions=param_distributions, n_iter=20,\n","    cv=10, verbose=1,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Para medir la precisión del modelo a entrenar antes de enviar a Kaggle los resultados con los datos de test proporcionados, hacemos una pequeña partición de los datos de entrenamiento para poder contar con nuestros propios datos de test:"]},{"cell_type":"code","execution_count":141,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Extracción de variable objetivo y variables seleccionadas\n","y = train_data[\"Survived\"]\n","X = train_data[features]\n","\n","# Como el dataset no es muy grande, solo reservamos un 15% de los datos para test\n","\n","data_train, data_test, target_train, target_test = train_test_split(\n","    X, y, random_state=42, test_size=0.15) "]},{"cell_type":"markdown","metadata":{},"source":["Y ahora si, realizamos nuestro entrenamiento del modelo usando una búsqueda aleatoria de la mejor combinación de hiperparámetros:"]},{"cell_type":"code","execution_count":142,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 20 candidates, totalling 200 fits\n","Precisión del modelo en datos de test con la combinación de hiperparámetros: 0.8209\n"]}],"source":["# Búsqueda de hiperparámetros y entrenamiento\n","\n","model_random_search.fit(data_train, target_train)\n","\n","# Precisión con datos de test propios\n","\n","accuracy = model_random_search.score(data_test, target_test)\n","\n","print(f\"Precisión del modelo en datos de test con la combinación de hiperparámetros: \"\n","      f\"{accuracy:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["Por último, hacemos las predicciones sobre los datos de test de Kaggle y los guardamos, para hacer el envío a la competición:"]},{"cell_type":"code","execution_count":143,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fichero para Kaggle generado correctamente.\n"]}],"source":["predictions = model_random_search.predict(test_data)\n","\n","output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n","output.to_csv('submission.csv', index=False)\n","print(\"Fichero para Kaggle generado correctamente.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":4}
